{"pages":[{"title":"about.md","text":"","link":"/about-md/index.html"}],"posts":[{"title":"Bigdata learning","text":"菜鸡的学习过程点滴记录 1. Hadoop环境搭建1.1 安装虚拟机以及Centos操作系统我的组合是VMware16、Centos8和Hadoop2.7.7。建议Centos系统是1个graph模式和2个multi模式。 图形界面和命令行切换： 1234systemctl get-default # 查看目前的启动方式 multi-user是命令行模式，graphical是图形界面模式systemctl set-default graphical.target # 设置为图形界面systemctl set-default multi-user.target # 设置为命令行界面reboot # 重启 如果开始安装的是命令行界面，则还需要安装gnome图形界面。 1234yum groupinstall -y &quot;Server with GUI&quot; # 安装图形界面软件包systemctl set-default graphical.targetsystemctl enable gdm --now # 设置图形界面开机自启动reboot # 重启 Centos8右键菜单默认没有打开终端选项，我们可以设置快捷键来启动它 1234567设置 -&gt; 设备 -&gt; display -&gt; keyboard -&gt; 底部添加选项 -&gt; 点击名称: terminal命令: /usr/bin/gnome-terminal快捷键: 自己喜欢的组合键即可，我的是Ctrl+Alt+T 1.2 Hadoop的搭建参考 Hadoop安装教程_单机/伪分布式配置_Hadoop2.6.0(2.7.1)/Ubuntu14.04(16.04) Hadoop集群安装配置教程_Hadoop2.6.0_Ubuntu/CentOS 一般的步骤是 关闭并禁用防火墙 创建hadoop用户 更新yum 安装java环境 安装hadoop并配置 克隆虚拟机 配置网络 修改slave的配置文件 配置ssh免密登录 在master上开启Hadoop 过程中最容易出现的错误是最后两步，如果ssh配置后不行的话，可以试参考 ssh配置authorized_keys后仍然需要输入密码的问题 不过具体问题还得看日志，根据日志来解决问题。 2. 编译运行WordCount程序参考 使用命令行编译打包运行自己的MapReduce程序 Hadoop2.6.0 使用Eclipse编译运行MapReduce程序_Hadoop2.6.0_Ubuntu/CentOS 其中eclipse在Centos下的安装程序链接失效，截止2020.10.04，http://eclipse.bluemix.net/packages/2020-09/data/eclipse-java-2020-09-R-linux-gtk-x86_64.tar.gz 还可以下载。 过程中遇到的问题 Input path does not exist: hdfs://master:9000/user/hadoop/input 123hdfs dfs -mkdir -p /user/hadoophdfs dfs -mkdir input/usr/local/hadoop/bin/hadoop fs -put ./input input There are 0 datanode(s) running and no node(s) are excluded in this operation. 1首先见检查三台机器的网络连接，没有问题的话执行$HADOOP_HOME/sbin/stop-all.sh，关闭Hadoop之后重新启动。 Warn: Unable to load native-hadoop library for your platform… using builtin-java classes where applicable 123在~/.bashrc下加入export JAVA_LIBRAY_PATH=/usr/local/hadoop/lib/native并source ~/.bashrc即可 运行eclipse提示java版本必须在11及以上 123yum安装jdk11alternatives的使用.bashrc的配置 参考 Linux下怎么切换使用两个版本的JDK Failed: java.net.SocketException: Network is unreachable 检查Hadoop集群的网络连接 3. HDFS与Shell命令的交互参考 分布式文件系统HDFS 学习指南 运行HDFSFileIfExist.java时except Connection refused 首先检查/etc/hosts是否有localhost IP映射到hadoop namenode，也可以直接在源代码中修改localhost为namenode的IP。 4. Spark安装与基础使用参考 Spark安装与基础使用 运行spark-shell失败Failed to initialize compiler: object java.lang.Object in compiler mirror not found. 看完报错日志里的 123456error: error while loading package, Missing dependency &apos;object java.lang.Object in compiler mirror&apos;, required by /usr/local/spark/lib/spark-assembly-1.6.0-hadoop2.2.0.jar(scala/package.class)error: error while loading package, Missing dependency &apos;object java.lang.Object in compiler mirror&apos;, required by /usr/local/spark/lib/spark-assembly-1.6.0-hadoop2.2.0.jar(scala/runtime/package.class)** Note that as of 2.8 scala does not assume use of the java classpath.** For the old behavior pass -usejavacp to scala, or if using a Settings** object programatically, settings.usejavacp.value = true. 大概就知道是哪里出错了。 首先检查是否安装Scala，然后java -version检查Java版本，接着查看环境变量里面JAVA_HOME是否是1.8x版本的路径，最后检查 123cd /your/spark/home/vim ./bin/spark-shell# settings.usejavacp.value = true. 5. HBase安装 参考 ZooKeeper 和 HBase 官方文档中文版 先安装zookeeper，接着再安装下载hbase包。 有一个步骤一定要注意，就是在配置完成后修改 /hbase/home/conf/hbase-env.sh，找到HBASE_PID_DIR，默认是/tmp文件夹，由于该文件夹下内容非常容易丢失，我们可以按照模板给的/var/hadoop/pids，mkdir -p创建文件夹。不然stop hbase时会出现 No such file or directory问题。 最后安装启动顺序启动即可，即hadoop-&gt;zookeeper-&gt;hbase，关闭顺序反过来即可。 不知道是不是错觉，自带的zoo.cfg配置文件模板不能直接用，反正我cp一份出来配置失败。 6. TensorFlow环境搭建如果有在线环境可以参考 TensorFlow官网 CentOS安装可能会出现 is not a supported wheel on this platform报错。这时候就需要修改文件名 12import pipprint(pip.pep425tags.get_supported()) 查看python支持的文件名中的字符。 譬如我的python版本是3.6，安装的原名字是tensorflow_cpu-2.3.0-cp36-cp36m-manylinux2010_x86_64.whl，就需要修改为tensorflow-2.3.0-cp36-cp36m-manylinux1_x86_64.whl。 这是去年比赛的答案 Linux安装python3环境使用安装包安装python3.6解压 12345678tar -zxvf Python-3.6.3.tgzcd Python-3.6.3yum -y install zlib* openssl* # 先安装依赖包./configure --prefix=/usr/local/python3 # 指定安装目录，开始安装make &amp; make installln -s /usr/local/python3/bin/python3 /usr/bin/python3 # 建立软连接ln -s /usr/local/python3/bin/pip3 /usr/bin/pippip install tensorflow-1.1.0rc1-cp36-cp36m-manylinux1_x86_64.whl # 使用pip安装tensorflow Demo Configurationhdfs-site.xml 1234567891011121314151617181920212223&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;3&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt; &lt;value&gt;master:50090&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;file:/usr/local/hadoop/tmp/dfs/name&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;file:/usr/local/hadoop/tmp/dfs/data&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.max.transfer.threads&lt;/name&gt; &lt;value&gt;4096&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; core-site.xml 123456789101112&lt;configuration&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;file:/usr/local/hadoop/tmp&lt;/value&gt; &lt;description&gt;Abase for other temporary directories.&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://master:9000&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; zoo.cfg 12345678tickTime=2000dataDir=/usr/local/zookeeper/dataclientPort=2181initLimit=10syncLimit=4server.1=master:2888:3888server.2=slaver1:2888:3888server.3=slaver2:2888:3888 hbase-site.xml 123456789101112131415&lt;configuration&gt; &lt;property&gt; &lt;name&gt;hbase.rootdir&lt;/name&gt; &lt;value&gt;hdfs://master:9000/hbase&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.cluster.distributed&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt; &lt;value&gt;master,slaver1,slaver2&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; hbase-env.sh 123export HBASE_PID_DIR=/var/hadoop/pidsexport HBASE_MANAGES_ZK=false","link":"/2020/10/05/Bigdata%20learning/"},{"title":"Data analysis","text":"常用的统计图折线图: 折线的上升或者下降表示统计数量的增减变化的统计图。（变化） 直方图: 一系列高低不等的纵向条纹或线段表示数据分布情况。（统计） 条形图: 排列在工作表的列或行中的数据可以绘制到条形图中。（统计） 散点图: 多个坐标点，考察坐标点分布，判断变量之间是否存在某种关联。（分布规律） Python可视化依赖的库matplotlib 12345678910111213141516171819202122232425262728293031323334from matplotlib import pyplot as pltplt.rcParams[&apos;font.sans-serif&apos;] = [&apos;SimHei&apos;] # 指定默认字体：解决plot不能显示中文问题plt.rcParams[&apos;axes.unicode_minus&apos;] = False # 解决保存图像是负号&apos;-&apos;显示为方块的问题plt.figure(figsize=(20, 8), dpi=80) # 调用figure实例设置图片大小 dpi参数让图片更清晰# 绘制折线图，有几条调用几次plot方法。plt.plot(x, y, # x、y表示在x轴和y轴的数据 label=&apos;图例名称&apos;, # 设置图例名称 linestyle=&apos;-&apos;, # 设置图线的风格 color=&apos;purple&apos;, # 设置图线的颜色 alpha=0.3) # 设置图线透明度# ...# plt.plot(x, y)label_x = list[x轴的描述信息]plt.xticks(list[x], # 设置x轴的刻度 list[x][::2]兼容步长 label_x, # 设置x轴的标签 ratotion=90) # 设置旋转的度数label_y = list[y轴的描述信息]plt.yticks(list[y], label_y) # 设置y轴的刻度以及标签plt.xlabel(&apos;添加x轴的表示信息&apos;)plt.ylabel(&apos;添加y轴的表示信息&apos;)plt.title(&apos;标题&apos;)plt.grid(alpha=0.3) # 添加网格并设置透明度plt.legend(&apos;添加图例&apos;) # 对应plot()方法中的label参数，解释线段表示的内容plt.savefig(&apos;name.png&apos;) # 保存图片到本地plt.show() # 画出图形 123456789101112# 几种图例的方法# 折线图plt.plot()# 散点图plt.scatter(x, y)# 条形图plt.bar(list[x], width=&apos;线条宽度&apos;)# 直方图# hist方法是用于没有被统计过的数据plt.hist(a, # a为需要统计的数据 num_bins, # num_bins为分组的组数 normed=1) # normal参数为是否绘制频率分布直方图，默认为频数直方图 numpy定义是一个Python中做科学计算的基础库，重在数值计算，多用于大型、多维数组上执行数值运算。 使用123456789101112import numpy as np# 三种创建数组的方法 [1, 2, 3, 4, 5]a = np.array([1, 2, 3, 4, 5])b = np.array(range(1, 6))c = np.arange(1, 6)print(type(a)) # 返回a的数据结构类型print(a.dtype) # dtype返回数据元素的数据类型 必须是同一数据类型print(a.astype(np.float)) # 返回临时修改的数据类型的数组b = np.array([0.048, 0.266])print(np.round(b,2)) # 设置b的输出格式为保留两位小数 形状123456789import numpy as npa = np.array([[3, 4, 5, 6, 7, 8], [4, 5, 6, 7, 8, 9]])print(a.shape) # (2, 6)a.reshape(3, 4)print(a) # [[3, 4, 5, 6, 7, 8], [4, 5, 6, 7, 8, 9]]a = a.reshape(3, 4)print(a) #[[3 4 5 6] [7 8 4 5] [6 7 8 9]] 这里的a和第三行的a不是同一个a","link":"/2020/10/23/Data%20analysis/"},{"title":"Learning Algorithm.md","text":"Wikipedia中的定义深度优先搜索算法（英语：Depth-First-Search，DFS）是一种用于遍历或搜索树或图的算法。这个算法会尽可能深的搜索树的分支。当节点v的所在边都己被探寻过，搜索将回溯到发现节点v的那条边的起始节点。这一过程一直进行到已发现从源节点可达的所有节点为止。如果还存在未被发现的节点，则选择其中一个作为源节点并重复以上过程，整个进程反复进行直到所有节点都被访问为止。[1](p603)这种算法不会根据图的结构等信息调整执行策略[来源请求]。 广度优先搜索算法（英语：Breadth-First Search，缩写为BFS），又译作宽度优先搜索，或横向优先搜索，是一种图形搜索算法。简单的说，BFS是从根节点开始，沿着树的宽度遍历树的节点。如果所有节点均被访问，则算法中止。广度优先搜索的实现一般采用open-closed表。 C/C++语言描述DFS实现方法: 首先将根节点放入stack中。 从stack中取出第一个节点，并检验它是否为目标。 重复步骤2。 如果不存在未检测过的直接子节点。 重复步骤4。 若stack为空，表示整张图都检查过了——亦即图中没有欲搜寻的目标。结束搜寻并回传“找不到目标”。 DFS的C模板大概如下: 1234567891011121314151617181920212223242526272829303132333435363738394041#include&lt;stdio.h&gt;int min = 99999999; // 定义最短路径int vis[100] = 0; // 标记数组，此路是否走过int a[100] = 0; // 要遍历的路void DFS(int x, int step){ if(x == 终点) // 到终点的决策 { if(step &lt; min) min = step; return; } if(a[x] == 1 &amp;&amp; vis[x] == 0) // 没在终点而且没有访问过的决策 { vis[x] = 1; // 标记为已走过 dfs(x + 1, step + 1); // 调用dfs vis[x] = 0 // 回溯时复位 } return;}int main(){ // 输入参数，初始化 ... // 设置起点并将其标记为已访问 vis[startx] = 1; // 调用函数 dfs(startx, 0); // 输出结果 printf(&quot;%d\\n&quot;, min); return 0;} BFS实现方法 首先将根节点放入队列中。 从队列中取出第一个节点，并检验它是否为目标。 如果找到目标，则结束搜索并回传结果。 否则将它所有尚未检验过的直接子节点加入队列中。 若队列为空，表示整张图都检查过了——亦即图中没有欲搜索的目标。结束搜索并回传“找不到目标”。 重复步骤2。 BFS的C++模板大概如下: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051#include&lt;bit/stdc++.h&gt;using namespace std;int vis[100] = 0; // 标记数组，此路是否走过int a[100] = 0; // 要遍历的路int flag = 0;struct point{ int x; int step;};queue&lt;note&gt; r;int main(){ // 输入参数，初始化 ... point start; start.x = startx; start.step = 0; r.push(start); vis[startx] = 1; // 设置起点并将其标记为已访问 while(!r.empty()) { int x = r.front().x; if(x == 终点) // 到终点的决策 { flag = 1; printf(&quot;%d\\n&quot;, r.front().step); break; } if(a[x] == 1 &amp;&amp; vis[x] == 0) // 没在终点而且没有访问过的决策 { // 入队 point temp; temp.x = x; temp.step = r.front().step + 1; r.push(temp); v[x] = 1; } r.pop(); // 拓展完成之后首节点出队 } if(flag == 0) printf(&quot;NO Answer.&quot;); return 0;} 例题待更新…","link":"/2020/10/20/Learning%20Algorithm/"}],"tags":[{"name":"Bigdata","slug":"Bigdata","link":"/tags/Bigdata/"},{"name":"C Data Struct","slug":"C-Data-Struct","link":"/tags/C-Data-Struct/"},{"name":"visualize","slug":"visualize","link":"/tags/visualize/"}],"categories":[{"name":"Bigdata","slug":"Bigdata","link":"/categories/Bigdata/"},{"name":"Algorithm","slug":"Algorithm","link":"/categories/Algorithm/"},{"name":"Data analysis","slug":"Data-analysis","link":"/categories/Data-analysis/"}]}