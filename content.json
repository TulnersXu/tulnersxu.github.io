{"pages":[{"title":"about.md","text":"","link":"/about-md/index.html"}],"posts":[{"title":"Bigdata learning","text":"菜鸡的学习过程点滴记录 1. Hadoop环境搭建1.1 安装虚拟机以及Centos操作系统我的组合是VMware16、Centos8和Hadoop2.7.7。建议Centos系统是1个graph模式和2个multi模式。 图形界面和命令行切换： 1234systemctl get-default # 查看目前的启动方式 multi-user是命令行模式，graphical是图形界面模式systemctl set-default graphical.target # 设置为图形界面systemctl set-default multi-user.target # 设置为命令行界面reboot # 重启 如果开始安装的是命令行界面，则还需要安装gnome图形界面。 1234yum groupinstall -y &quot;Server with GUI&quot; # 安装图形界面软件包systemctl set-default graphical.targetsystemctl enable gdm --now # 设置图形界面开机自启动reboot # 重启 Centos8右键菜单默认没有打开终端选项，我们可以设置快捷键来启动它 1234567设置 -&gt; 设备 -&gt; display -&gt; keyboard -&gt; 底部添加选项 -&gt; 点击名称: terminal命令: /usr/bin/gnome-terminal快捷键: 自己喜欢的组合键即可，我的是Ctrl+Alt+T 1.2 Hadoop的搭建参考 Hadoop安装教程_单机/伪分布式配置_Hadoop2.6.0(2.7.1)/Ubuntu14.04(16.04) Hadoop集群安装配置教程_Hadoop2.6.0_Ubuntu/CentOS 一般的步骤是 关闭并禁用防火墙 创建hadoop用户 更新yum 安装java环境 安装hadoop并配置 克隆虚拟机 配置网络 修改slave的配置文件 配置ssh免密登录 在master上开启Hadoop 过程中最容易出现的错误是最后两步，如果ssh配置后不行的话，可以试参考 ssh配置authorized_keys后仍然需要输入密码的问题 不过具体问题还得看日志，根据日志来解决问题。 2. 编译运行WordCount程序参考 使用命令行编译打包运行自己的MapReduce程序 Hadoop2.6.0 使用Eclipse编译运行MapReduce程序_Hadoop2.6.0_Ubuntu/CentOS 其中eclipse在Centos下的安装程序链接失效，截止2020.10.04，http://eclipse.bluemix.net/packages/2020-09/data/eclipse-java-2020-09-R-linux-gtk-x86_64.tar.gz 还可以下载。 过程中遇到的问题 Input path does not exist: hdfs://master:9000/user/hadoop/input 123hdfs dfs -mkdir -p /user/hadoophdfs dfs -mkdir input/usr/local/hadoop/bin/hadoop fs -put ./input input There are 0 datanode(s) running and no node(s) are excluded in this operation. 1首先见检查三台机器的网络连接，没有问题的话执行$HADOOP_HOME/sbin/stop-all.sh，关闭Hadoop之后重新启动。 Warn: Unable to load native-hadoop library for your platform… using builtin-java classes where applicable 123在~/.bashrc下加入export JAVA_LIBRAY_PATH=/usr/local/hadoop/lib/native并source ~/.bashrc即可 运行eclipse提示java版本必须在11及以上 123yum安装jdk11alternatives的使用.bashrc的配置 参考 Linux下怎么切换使用两个版本的JDK Failed: java.net.SocketException: Network is unreachable 检查Hadoop集群的网络连接 3. HDFS与Shell命令的交互参考 分布式文件系统HDFS 学习指南 运行HDFSFileIfExist.java时except Connection refused 首先检查/etc/hosts是否有localhost IP映射到hadoop namenode，也可以直接在源代码中修改localhost为namenode的IP。 4. Spark安装与基础使用参考 Spark安装与基础使用 运行spark-shell失败Failed to initialize compiler: object java.lang.Object in compiler mirror not found. 看完报错日志里的 123456error: error while loading package, Missing dependency &apos;object java.lang.Object in compiler mirror&apos;, required by /usr/local/spark/lib/spark-assembly-1.6.0-hadoop2.2.0.jar(scala/package.class)error: error while loading package, Missing dependency &apos;object java.lang.Object in compiler mirror&apos;, required by /usr/local/spark/lib/spark-assembly-1.6.0-hadoop2.2.0.jar(scala/runtime/package.class)** Note that as of 2.8 scala does not assume use of the java classpath.** For the old behavior pass -usejavacp to scala, or if using a Settings** object programatically, settings.usejavacp.value = true. 大概就知道是哪里出错了。 首先检查是否安装Scala，然后java -version检查Java版本，接着查看环境变量里面JAVA_HOME是否是1.8x版本的路径，最后检查 123cd /your/spark/home/vim ./bin/spark-shell# settings.usejavacp.value = true. 5. HBase安装 参考 ZooKeeper 和 HBase 官方文档中文版 先安装zookeeper，接着再安装下载hbase包。 有一个步骤一定要注意，就是在配置完成后修改 /hbase/home/conf/hbase-env.sh，找到HBASE_PID_DIR，默认是/tmp文件夹，由于该文件夹下内容非常容易丢失，我们可以按照模板给的/var/hadoop/pids，mkdir -p创建文件夹。不然stop hbase时会出现 No such file or directory问题。 最后安装启动顺序启动即可，即hadoop-&gt;zookeeper-&gt;hbase，关闭顺序反过来即可。 不知道是不是错觉，自带的zoo.cfg配置文件模板不能直接用，反正我cp一份出来配置失败。 6. TensorFlow环境搭建如果有在线环境可以参考 TensorFlow官网 CentOS安装可能会出现 is not a supported wheel on this platform报错。这时候就需要修改文件名 12import pipprint(pip.pep425tags.get_supported()) 查看python支持的文件名中的字符。 譬如我的python版本是3.6，安装的原名字是tensorflow_cpu-2.3.0-cp36-cp36m-manylinux2010_x86_64.whl，就需要修改为tensorflow-2.3.0-cp36-cp36m-manylinux1_x86_64.whl。 这是去年比赛的答案 Linux安装python3环境使用安装包安装python3.6解压 12345678tar -zxvf Python-3.6.3.tgzcd Python-3.6.3yum -y install zlib* openssl* # 先安装依赖包./configure --prefix=/usr/local/python3 # 指定安装目录，开始安装make &amp; make installln -s /usr/local/python3/bin/python3 /usr/bin/python3 # 建立软连接ln -s /usr/local/python3/bin/pip3 /usr/bin/pippip install tensorflow-1.1.0rc1-cp36-cp36m-manylinux1_x86_64.whl # 使用pip安装tensorflow Demo Configurationhdfs-site.xml 1234567891011121314151617181920212223&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;3&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt; &lt;value&gt;master:50090&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;file:/usr/local/hadoop/tmp/dfs/name&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;file:/usr/local/hadoop/tmp/dfs/data&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.max.transfer.threads&lt;/name&gt; &lt;value&gt;4096&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; core-site.xml 123456789101112&lt;configuration&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;file:/usr/local/hadoop/tmp&lt;/value&gt; &lt;description&gt;Abase for other temporary directories.&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://master:9000&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; zoo.cfg 12345678tickTime=2000dataDir=/usr/local/zookeeper/dataclientPort=2181initLimit=10syncLimit=4server.1=master:2888:3888server.2=slaver1:2888:3888server.3=slaver2:2888:3888 hbase-site.xml 123456789101112131415&lt;configuration&gt; &lt;property&gt; &lt;name&gt;hbase.rootdir&lt;/name&gt; &lt;value&gt;hdfs://master:9000/hbase&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.cluster.distributed&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt; &lt;value&gt;master,slaver1,slaver2&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; hbase-env.sh 123export HBASE_PID_DIR=/var/hadoop/pidsexport HBASE_MANAGES_ZK=false","link":"/2020/10/05/Bigdata-learning/"},{"title":"Learning Algorithm.md","text":"Wikipedia中的定义深度优先搜索算法（英语：Depth-First-Search，DFS）是一种用于遍历或搜索树或图的算法。这个算法会尽可能深的搜索树的分支。当节点v的所在边都己被探寻过，搜索将回溯到发现节点v的那条边的起始节点。这一过程一直进行到已发现从源节点可达的所有节点为止。如果还存在未被发现的节点，则选择其中一个作为源节点并重复以上过程，整个进程反复进行直到所有节点都被访问为止。[1](p603)这种算法不会根据图的结构等信息调整执行策略[来源请求]。 广度优先搜索算法（英语：Breadth-First Search，缩写为BFS），又译作宽度优先搜索，或横向优先搜索，是一种图形搜索算法。简单的说，BFS是从根节点开始，沿着树的宽度遍历树的节点。如果所有节点均被访问，则算法中止。广度优先搜索的实现一般采用open-closed表。 C/C++语言描述DFS实现方法: 首先将根节点放入stack中。 从stack中取出第一个节点，并检验它是否为目标。 重复步骤2。 如果不存在未检测过的直接子节点。 重复步骤4。 若stack为空，表示整张图都检查过了——亦即图中没有欲搜寻的目标。结束搜寻并回传“找不到目标”。 DFS的C模板大概如下: 1234567891011121314151617181920212223242526272829303132333435363738394041#include&lt;stdio.h&gt;int min = 99999999; // 定义最短路径int vis[100] = 0; // 标记数组，此路是否走过int a[100] = 0; // 要遍历的路void DFS(int x, int step){ if(x == 终点) // 到终点的决策 { if(step &lt; min) min = step; return; } if(a[x] == 1 &amp;&amp; vis[x] == 0) // 没在终点而且没有访问过的决策 { vis[x] = 1; // 标记为已走过 dfs(x + 1, step + 1); // 调用dfs vis[x] = 0 // 回溯时复位 } return;}int main(){ // 输入参数，初始化 ... // 设置起点并将其标记为已访问 vis[startx] = 1; // 调用函数 dfs(startx, 0); // 输出结果 printf(&quot;%d\\n&quot;, min); return 0;} BFS实现方法 首先将根节点放入队列中。 从队列中取出第一个节点，并检验它是否为目标。 如果找到目标，则结束搜索并回传结果。 否则将它所有尚未检验过的直接子节点加入队列中。 若队列为空，表示整张图都检查过了——亦即图中没有欲搜索的目标。结束搜索并回传“找不到目标”。 重复步骤2。 BFS的C++模板大概如下: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051#include&lt;bit/stdc++.h&gt;using namespace std;int vis[100] = 0; // 标记数组，此路是否走过int a[100] = 0; // 要遍历的路int flag = 0;struct point{ int x; int step;};queue&lt;note&gt; r;int main(){ // 输入参数，初始化 ... point start; start.x = startx; start.step = 0; r.push(start); vis[startx] = 1; // 设置起点并将其标记为已访问 while(!r.empty()) { int x = r.front().x; if(x == 终点) // 到终点的决策 { flag = 1; printf(&quot;%d\\n&quot;, r.front().step); break; } if(a[x] == 1 &amp;&amp; vis[x] == 0) // 没在终点而且没有访问过的决策 { // 入队 point temp; temp.x = x; temp.step = r.front().step + 1; r.push(temp); v[x] = 1; } r.pop(); // 拓展完成之后首节点出队 } if(flag == 0) printf(&quot;NO Answer.&quot;); return 0;} 例题待更新…","link":"/2020/10/20/Learning-Algorithm/"}],"tags":[{"name":"Bigdata","slug":"Bigdata","link":"/tags/Bigdata/"},{"name":"C Data Struct","slug":"C-Data-Struct","link":"/tags/C-Data-Struct/"}],"categories":[{"name":"Bigdata","slug":"Bigdata","link":"/categories/Bigdata/"},{"name":"Algorithm","slug":"Algorithm","link":"/categories/Algorithm/"}]}