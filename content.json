{"pages":[{"title":"about.md","text":"","link":"/about-md/index.html"}],"posts":[{"title":"Bigdata learning","text":"菜鸡的学习过程点滴记录 1. Hadoop环境搭建1.1 安装虚拟机以及Centos操作系统我的组合是VMware16、Centos8和Hadoop2.7.7。建议Centos系统是1个graph模式和2个multi模式。 图形界面和命令行切换： 1234systemctl get-default # 查看目前的启动方式 multi-user是命令行模式，graphical是图形界面模式systemctl set-default graphical.target # 设置为图形界面systemctl set-default multi-user.target # 设置为命令行界面reboot # 重启 如果开始安装的是命令行界面，则还需要安装gnome图形界面。 1234yum groupinstall -y &quot;Server with GUI&quot; # 安装图形界面软件包systemctl set-default graphical.targetsystemctl enable gdm --now # 设置图形界面开机自启动reboot # 重启 Centos8右键菜单默认没有打开终端选项，我们可以设置快捷键来启动它 1234567设置 -&gt; 设备 -&gt; display -&gt; keyboard -&gt; 底部添加选项 -&gt; 点击名称: terminal命令: /usr/bin/gnome-terminal快捷键: 自己喜欢的组合键即可，我的是Ctrl+Alt+T 1.2 Hadoop的搭建参考 Hadoop安装教程_单机/伪分布式配置_Hadoop2.6.0(2.7.1)/Ubuntu14.04(16.04) Hadoop集群安装配置教程_Hadoop2.6.0_Ubuntu/CentOS 一般的步骤是 关闭并禁用防火墙 创建hadoop用户 更新yum 安装java环境 安装hadoop并配置 克隆虚拟机 配置网络 修改slave的配置文件 配置ssh免密登录 在master上开启Hadoop 过程中最容易出现的错误是最后两步，如果ssh配置后不行的话，可以试参考 ssh配置authorized_keys后仍然需要输入密码的问题 不过具体问题还得看日志，根据日志来解决问题。 2. 编译运行WordCount程序参考 使用命令行编译打包运行自己的MapReduce程序 Hadoop2.6.0 使用Eclipse编译运行MapReduce程序_Hadoop2.6.0_Ubuntu/CentOS 其中eclipse在Centos下的安装程序链接失效，截止2020.10.04，http://eclipse.bluemix.net/packages/2020-09/data/eclipse-java-2020-09-R-linux-gtk-x86_64.tar.gz 还可以下载。 过程中遇到的问题 Input path does not exist: hdfs://master:9000/user/hadoop/input 123hdfs dfs -mkdir -p /user/hadoophdfs dfs -mkdir input/usr/local/hadoop/bin/hadoop fs -put ./input input There are 0 datanode(s) running and no node(s) are excluded in this operation. 1首先见检查三台机器的网络连接，没有问题的话执行$HADOOP_HOME/sbin/stop-all.sh，关闭Hadoop之后重新启动。 Warn: Unable to load native-hadoop library for your platform… using builtin-java classes where applicable 123在~/.bashrc下加入export JAVA_LIBRAY_PATH=/usr/local/hadoop/lib/native并source ~/.bashrc即可 运行eclipse提示java版本必须在11及以上 123yum安装jdk11alternatives的使用.bashrc的配置 参考 Linux下怎么切换使用两个版本的JDK Failed: java.net.SocketException: Network is unreachable 检查Hadoop集群的网络连接 3. HDFS与Shell命令的交互参考 分布式文件系统HDFS 学习指南 运行HDFSFileIfExist.java时except Connection refused 首先检查/etc/hosts是否有localhost IP映射到hadoop namenode，也可以直接在源代码中修改localhost为namenode的IP。 4. Spark安装与基础使用参考 Spark安装与基础使用 运行spark-shell失败Failed to initialize compiler: object java.lang.Object in compiler mirror not found. 看完报错日志里的 123456error: error while loading package, Missing dependency &apos;object java.lang.Object in compiler mirror&apos;, required by /usr/local/spark/lib/spark-assembly-1.6.0-hadoop2.2.0.jar(scala/package.class)error: error while loading package, Missing dependency &apos;object java.lang.Object in compiler mirror&apos;, required by /usr/local/spark/lib/spark-assembly-1.6.0-hadoop2.2.0.jar(scala/runtime/package.class)** Note that as of 2.8 scala does not assume use of the java classpath.** For the old behavior pass -usejavacp to scala, or if using a Settings** object programatically, settings.usejavacp.value = true. 大概就知道是哪里出错了。 首先检查是否安装Scala，然后java -version检查Java版本，接着查看环境变量里面JAVA_HOME是否是1.8x版本的路径，最后检查 123cd /your/spark/home/vim ./bin/spark-shell# settings.usejavacp.value = true. 5. TensorFlow环境搭建 如果有在线环境可以参考 TensorFlow官网 CentOS安装可能会出现 is not a supported wheel on this platform报错。这时候就需要修改文件名 12import pipprint(pip.pep425tags.get_supported()) 查看python支持的文件名中的字符。 譬如我的python版本是3.6，安装的原名字是tensorflow_cpu-2.3.0-cp36-cp36m-manylinux2010_x86_64.whl，就需要修改为tensorflow-2.3.0-cp36-cp36m-manylinux1_x86_64.whl。 这是去年比赛的答案 Linux安装python3环境使用安装包安装python3.6解压 12345678tar -zxvf Python-3.6.3.tgzcd Python-3.6.3yum -y install zlib* openssl* # 先安装依赖包./configure --prefix=/usr/local/python3 # 指定安装目录，开始安装make &amp; make installln -s /usr/local/python3/bin/python3 /usr/bin/python3 # 建立软连接ln -s /usr/local/python3/bin/pip3 /usr/bin/pippip install tensorflow-1.1.0rc1-cp36-cp36m-manylinux1_x86_64.whl # 使用pip安装tensorflow","link":"/2020/10/05/Bigdata-learning/"}],"tags":[{"name":"Bigdata","slug":"Bigdata","link":"/tags/Bigdata/"}],"categories":[{"name":"Bigdata","slug":"Bigdata","link":"/categories/Bigdata/"}]}